#!/usr/bin/python

import glob
import os
import re
import shutil
import subprocess
import sys
import traceback
import json

verbose = False
if 'BUILDCACHE_VERBOSE' in os.environ and os.environ['BUILDCACHE_VERBOSE'] == '1':
    verbose = True

readonly_re = re.compile('.*O_RDONLY.*')
open_re = re.compile('open."([^"]+)", ([A-Za-z_\|]+)(, \d+)?. += (\d+).*')
write_re = re.compile('write.(\d+).*')

patterns_to_skip = [
    '/dev/.*',
    '/etc/.*',
    '/lib/.*',
    '/proc/.*',
    '/run/.*',
    '/sys/.*',
    '/tmp/.*',
    '/usr/.*',
    '.*/\\..*',
    ]

environment_variables_to_skip = [
    '.*EMACS.*',
    '.*SESSION_COOKIE.*',
    'DISPLAY',
    'LM_LICENSE_FILE',
    'LOGNAME',
    'MAIL',
    'MAKELEVEL',
    'MFLAGS',
    'MAKEFLAGS',
    'SHLVL',
    'TERM',
    'TERMCAP',
    'SSH.*',
    'USER',
]

environment_re_to_skip = [re.compile(p) for p in environment_variables_to_skip]

re_to_skip = []

filesRead = {}
filesWritten = {}
fdFile = {}
fdFlags = {}

def scanStraceFiles(tmpdir):
    for stracefile in glob.glob('%s/*' % tmpdir):
        for line in open(stracefile, 'r'):
            m = open_re.match(line)
            wm = write_re.match(line)
            if m:
                fname = os.path.abspath(m.group(1))
                flags =  m.group(2)

                fd = m.group(m.lastindex)
                fdFile[fd] = fname
                fdFlags[fd] = flags
                #print fd, fname, flags

                if readonly_re.match(flags):
                    if fname in filesRead:
                        filesRead[fname] += '|' + flags
                    else:
                        filesRead[fname] = flags
                else:
                    # might be a write, but we need further evidence
                    pass
            elif wm:
                fd = wm.group(1)
                if int(fd) <= 2:
                    continue
                if not (fd in fdFile):
                    #print 'unknown file for fd', fd
                    #print line
                    continue
                fname = fdFile[fd]
                flags = fdFlags[fd]
                #print fd, fname, flags
                if not fname in filesWritten:
                    filesWritten[fname] = flags
            else:
                #print 'no matching re: ', line[0:-1]
                pass

def writeContextFile(filename):
    if not os.path.exists(os.path.dirname(filename)):
        os.makedirs(os.path.dirname(filename))
    env = {}
    for k in os.environ:
        if len([p for p in environment_re_to_skip if p.match(k)]):
            continue
        env[k] = os.environ[k]
    context = {'argv': sys.argv,
               'env': env }
    f = open(filename, 'w+')
    f.write(json.dumps(context))
    f.close()

def updateFilesWrittenFile(cacheDir, filesWritten):
    filename = os.path.join(cacheDir, 'buildcache.fileswritten.json')
    if not os.path.exists(os.path.dirname(filename)):
        os.makedirs(os.path.dirname(filename))
    cwd = os.getcwd()
    info = {'filesWritten': [f for f in filesWritten],
            'cwd': cwd}
    f = open(filename, 'w+')
    f.write(json.dumps(info))
    f.close()

def readFilesWrittenFile(cacheDir):
    filename = os.path.join(cacheDir, 'buildcache.fileswritten.json')
    if not os.path.exists(os.path.dirname(filename)):
        return []
    f = open(filename, 'r')
    info = json.loads(f.read())
    f.close()
    return info

def writeFilesToCache(cacheDir, filesWritten):
    cwd = os.getcwd()
    for f in filesWritten:
        fname = os.path.relpath(f, cwd)
        cname = os.path.join(cacheDir, fname)
        if verbose:
            print 'caching', fname
        cdir = os.path.dirname(cname)
        if not os.path.isdir(cdir):
            os.makedirs(cdir)
        shutil.copy2(fname, cname)

def readFilesFromCache(cacheDir):
    info = readFilesWrittenFile(cacheDir)
    filesWritten = info['filesWritten']
    cwd = info['cwd']
    for f in filesWritten:
        fname = os.path.relpath(f, cwd)
        cname = os.path.join(cacheDir, fname)
        if verbose:
            print 'restoring', fname
        shutil.copy2(cname, fname)

def uniqFiles(files):
    uniqfiles = []
    for f in files:
        skip = False
        for re in re_to_skip:
            m = re.match(f)
            if m:
                skip = True
                break
        if skip:
            continue
        uniqfiles.append(f)
    uniqfiles.sort()
    return uniqfiles    

def buildcache_cachedir():
    if not 'BUILDCACHE_CACHEDIR' in os.environ:
        print 'no BUILDCACHE_CACHEDIR'
        #print os.environ
        return None
    cachedir = os.environ['BUILDCACHE_CACHEDIR']
    return cachedir
def buildcache_outputdir():
    if not 'BUILDCACHE_OUTPUTDIR' in os.environ:
        return os.getcwd()
    outputdir = os.environ['BUILDCACHE_OUTPUTDIR']
    return outputdir

def update_md5sum(md5sum):
    cachedir = buildcache_cachedir()
    if not cachedir:
        return
    if not os.path.exists(cachedir):
        os.makedirs(cachedir)
    f = open(os.path.join(cachedir, 'buildcache.md5sum'), 'w+')
    rc = f.write(md5sum)
    f.close()

def check_md5sum():
    cachedir = buildcache_cachedir()
    if not cachedir:
        return False
    if not os.path.exists(cachedir):
        return False
    p = subprocess.Popen(['md5sum', '-c', os.path.join(cachedir, 'buildcache.md5sum')], stdout=subprocess.PIPE)
    p.wait()
    if verbose:
        print p.stdout.read()
    return p.returncode
    

tmpdir = '/tmp/buildcache-%d' % os.getpid()
os.makedirs(tmpdir)

args = ['strace', '-e', 'open,write', '-ff', '-o', '%s/strace' % tmpdir] + sys.argv[1:]

processpath = subprocess.check_output(['which', sys.argv[1]])
processpath = os.path.dirname(processpath)
if processpath.endswith('/bin'):
    processpath = os.path.dirname(processpath)
patterns_to_skip.append(os.path.join(processpath, '.*'))
#print patterns_to_skip

re_to_skip = [re.compile(pattern) for pattern in patterns_to_skip]

cache_dir = buildcache_cachedir()
output_dir = buildcache_outputdir()
context_file_name = os.path.join(output_dir, 'buildcache.context.json')

writeContextFile(context_file_name)

if os.path.exists(cache_dir) and (check_md5sum() == 0):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    print '%s: using cached result' % sys.argv[0]
    readFilesFromCache(cache_dir)
    sys.exit(0)

returncode = subprocess.call(args)

if returncode == 0:
    try:
        scanStraceFiles(tmpdir)
        cache_dir = buildcache_cachedir()
        output_dir = os.path.abspath(buildcache_outputdir())
        if verbose:
            print 'footprint: ============================================================'
            for f in uniqFiles(filesRead):
                print f, filesRead[f]
            print 'output:    ============================================================'
            for f in uniqFiles(filesWritten):
                print f, filesWritten[f]
            print '======================================================================='
        footprint = [context_file_name]
        for uf in uniqFiles(filesRead):
            if uf in filesWritten:
                continue
            if os.path.abspath(uf).startswith(output_dir):
                continue
            if not os.path.isfile(uf):
                #vivado seems to open directories
                continue
            footprint.append(uf)
        md5sum = subprocess.check_output(['md5sum'] + footprint)
        if verbose:
            print md5sum
        update_md5sum(md5sum)
        filtered_files_written = [f for f in filesWritten if not len([p for p in re_to_skip if p.match(f)])]
        updateFilesWrittenFile(cache_dir, filtered_files_written)
        writeFilesToCache(cache_dir, filtered_files_written)
        check_md5sum()

    except:
        print "Unexpected error:", sys.exc_info()
        print traceback.format_exc()

    shutil.rmtree(tmpdir)

sys.exit(returncode)
