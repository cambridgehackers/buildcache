#!/usr/bin/python

import glob
import os
import re
import shutil
import subprocess
import sys
import traceback
import json
import hashlib

verbose = False
if 'BUILDCACHE_VERBOSE' in os.environ and os.environ['BUILDCACHE_VERBOSE'] == '1':
    verbose = True
debug = False
if 'BUILDCACHE_DEBUG' in os.environ and os.environ['BUILDCACHE_DEBUG'] == '1':
    debug = True

readonly_re = re.compile('.*O_RDONLY.*')
open_re = re.compile('open."([^"]+)", ([A-Za-z_\|]+)(, \d+)?. += (\d+).*')
write_re = re.compile('write.(\d+).*')

patterns_to_skip = [
    '/dev/.*',
    '/etc/.*',
    '/lib/.*',
    '/proc/.*',
    '/run/.*',
    '/sys/.*',
    '/tmp/.*',
    '/usr/.*',
    '.*/\\..*',
    ]

environment_variables_to_skip = [
    '.*EMACS.*',
    '.*SESSION_COOKIE.*',
    'BUILDCACHE.*',
    'COLUMNS',
    'OLDPWD',
    'DISPLAY',
    'LM_LICENSE_FILE',
    'LOGNAME',
    'MAIL',
    'MAKELEVEL',
    'MFLAGS',
    'MAKEFLAGS',
    'SHLVL',
    'TERM',
    'TERMCAP',
    'SSH.*',
    'USER',
    'WINDOW'
]

environment_re_to_skip = [re.compile(p) for p in environment_variables_to_skip]

re_to_skip = []

filesRead = {}
filesWritten = {}
fdFile = {}
fdFlags = {}

## python 2.6 does not have subprocess.check_output
def check_output(cmd):
    p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
    return p.stdout.read()

def scanStraceFiles(tmpdir):
    for stracefile in glob.glob('%s/*' % tmpdir):
        for line in open(stracefile, 'r'):
            m = open_re.match(line)
            wm = write_re.match(line)
            if m:
                fname = os.path.abspath(m.group(1))
                flags =  m.group(2)

                fd = m.group(m.lastindex)
                fdFile[fd] = fname
                fdFlags[fd] = flags
                #print fd, fname, flags

                if readonly_re.match(flags):
                    if fname in filesRead:
                        filesRead[fname] += '|' + flags
                    else:
                        filesRead[fname] = flags
                else:
                    # might be a write, but we need further evidence
                    pass
            elif wm:
                fd = wm.group(1)
                if int(fd) <= 2:
                    continue
                if not (fd in fdFile):
                    #print 'unknown file for fd', fd
                    #print line
                    continue
                fname = fdFile[fd]
                flags = fdFlags[fd]
                #print fd, fname, flags
                if not fname in filesWritten:
                    filesWritten[fname] = flags
            else:
                #print 'no matching re: ', line[0:-1]
                pass

def writeContextFile(filename):
    if not os.path.exists(os.path.dirname(filename)):
        os.makedirs(os.path.dirname(filename))
    env = {}
    for k in os.environ:
        if len([p for p in environment_re_to_skip if p.match(k)]):
            continue
        env[k] = os.environ[k]
    context = {'argv': sys.argv,
               'env': env }
    f = open(filename, 'w+')
    jsonstr = json.dumps(context)
    f.write(jsonstr)
    f.close()
    m = hashlib.sha1(jsonstr)
    return m.hexdigest()

def updateFilesWrittenFile(cache_dir, filesWritten):
    filename = os.path.join(cache_dir, 'buildcache.fileswritten.json')
    if not os.path.exists(os.path.dirname(filename)):
        os.makedirs(os.path.dirname(filename))
    cwd = '/' #os.getcwd()
    info = {'filesWritten': [f for f in filesWritten],
            'cwd': cwd}
    f = open(filename, 'w+')
    f.write(json.dumps(info))
    f.close()

def readFilesWrittenFile(cache_dir):
    filename = os.path.join(cache_dir, 'buildcache.fileswritten.json')
    if not os.path.exists(os.path.dirname(filename)):
        return []
    f = open(filename, 'r')
    info = json.loads(f.read())
    f.close()
    return info

def writeFilesToCache(cache_dir, filesWritten):
    cwd = '/'
    for f in filesWritten:
        if not os.path.exists(f):
            if debug:
                print 'skipping non-existent file', f
            continue
        relname = os.path.relpath(f, cwd)
        cname = os.path.join(cache_dir, relname)
        if verbose:
            print 'caching', f
            print '     to', cname 
        cdir = os.path.dirname(cname)
        if not os.path.isdir(cdir):
            os.makedirs(cdir)
        shutil.copy2(f, cname)

def readFilesFromCache(cache_dir):
    info = readFilesWrittenFile(cache_dir)
    filesWritten = info['filesWritten']
    cwd = info['cwd']
    for f in filesWritten:
        relname = os.path.relpath(f, cwd)
        cname = os.path.join(cache_dir, relname)
        if not os.path.exists(cname):
            print 'cached file does not exist', cname
            continue
        if verbose:
            print 'restoring', f
        fdir = os.path.dirname(f)
        if not os.path.isdir(fdir):
            os.makedirs(fdir)
        try:
            shutil.copy2(cname, f)
        except:
            print 'Exception:', sys.exc_info()
            print 'Restoring cname %s to %s' % (cname, f)
            print traceback.format_exc()
        
def uniqFiles(files):
    uniqfiles = []
    for f in files:
        skip = False
        for re in re_to_skip:
            m = re.match(f)
            if m:
                skip = True
                break
        if skip:
            continue
        uniqfiles.append(f)
    uniqfiles.sort()
    return uniqfiles    

def buildcache_cachedir(key):
    if not 'BUILDCACHE_CACHEDIR' in os.environ:
        print 'no BUILDCACHE_CACHEDIR'
        #print os.environ
        return None
    cachedir = os.path.join(os.environ['BUILDCACHE_CACHEDIR'], key)
    return cachedir
def buildcache_outputdir():
    if not 'BUILDCACHE_OUTPUTDIR' in os.environ:
        return os.getcwd()
    outputdir = os.environ['BUILDCACHE_OUTPUTDIR']
    return outputdir

def update_md5sum(md5sum):
    if not cache_dir:
        return
    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir)
    f = open(os.path.join(cache_dir, 'buildcache.md5sum'), 'w+')
    rc = f.write(md5sum)
    f.close()

def check_md5sum():
    if not cache_dir:
        return False
    if not os.path.exists(cache_dir):
        return False
    p = subprocess.Popen(['md5sum', '-c', os.path.join(cache_dir, 'buildcache.md5sum')], stdout=subprocess.PIPE)
    p.wait()
    result = p.stdout.read()
    if debug:
        print result
    elif verbose:
        for line in result.split('\n'):
            if not line.endswith(' OK'):
                print line 
    return p.returncode
    

tmpdir = '/tmp/buildcache-%d' % os.getpid()
if os.path.isdir(tmpdir):
    shutil.rmtree(tmpdir)
os.makedirs(tmpdir)

processpath = check_output(['which', sys.argv[1]])
processpath = os.path.dirname(processpath)
if processpath.endswith('/bin'):
    processpath = os.path.dirname(processpath)
patterns_to_skip.append(os.path.join(processpath, '.*'))
#print patterns_to_skip

re_to_skip = [re.compile(pattern) for pattern in patterns_to_skip]

output_dir = buildcache_outputdir()
context_file_name = os.path.join(output_dir, 'buildcache.context.json')

sha1 = writeContextFile(context_file_name)
cache_dir = buildcache_cachedir(sha1)

if cache_dir and os.path.exists(cache_dir) and (check_md5sum() == 0):
    print '%s: using cached result' % sys.argv[0]
    readFilesFromCache(cache_dir)
    sys.exit(0)

if cache_dir:
    args = ['strace', '-e', 'open,write', '-ff', '-o', '%s/strace' % tmpdir] + sys.argv[1:]
else:
    args = sys.argv[1:]
returncode = subprocess.call(args)

if returncode == 0 and cache_dir:
    try:
        scanStraceFiles(tmpdir)
        output_dir = os.path.abspath(buildcache_outputdir())
        if debug:
            print 'footprint: ================================================================'
            for f in uniqFiles(filesRead):
                print f
        if verbose:
            print 'files to cache: ==========================================================='
            for f in uniqFiles(filesWritten):
                print f
            print '==========================================================================='
        footprint = [context_file_name]
        for uf in uniqFiles(filesRead):
            if uf in filesWritten:
                continue
            if os.path.abspath(uf).startswith(output_dir):
                continue
            if not os.path.isfile(uf):
                #vivado seems to open directories
                continue
            footprint.append(uf)
        md5sum = check_output(['md5sum'] + footprint)
        if debug:
            print md5sum
        update_md5sum(md5sum)
        filtered_files_written = [context_file_name] + [f for f in filesWritten if os.path.exists(f) and (not len([p for p in re_to_skip if p.match(f)]))]
        updateFilesWrittenFile(cache_dir, filtered_files_written)
        writeFilesToCache(cache_dir, filtered_files_written)
        check_md5sum()

    except:
        print "Unexpected error:", sys.exc_info()
        print traceback.format_exc()

    shutil.rmtree(tmpdir)

sys.exit(returncode)
